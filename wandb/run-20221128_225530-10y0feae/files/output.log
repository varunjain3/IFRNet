
Distributed Data Parallel Training IFRNet on Rank 0
2022-11-28 22:55:32:INFO:Namespace(batch_size=55, device=device(type='cuda', index=0), epochs=300, eval_interval=1, label_smoothing=0, local_rank=0, log_path='checkpoint/IFRNet', lr_end=1e-05, lr_start=0.0001, model_name='IFRNet', num_workers=10, resume_epoch=0, resume_path=None, world_size=2)
Traceback (most recent call last):
  File "train_vimeo90k.py", line 260, in <module>
    train(args, ddp_generator, model, ddp_discriminator)
  File "train_vimeo90k.py", line 101, in train
    discriminator_logits = ddp_discriminator(imgt_pred)
  File "/jet/home/kliu8/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
  File "/jet/home/kliu8/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1040, in forward
    output = self._run_ddp_forward(*inputs, **kwargs)
  File "/jet/home/kliu8/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 1000, in _run_ddp_forward
    return module_to_run(*inputs[0], **kwargs[0])
  File "/jet/home/kliu8/miniconda3/envs/torch/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1190, in _call_impl
    return forward_call(*input, **kwargs)
TypeError: forward() missing 3 required positional arguments: 'img1', 'embt', and 'imgt'